{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12776816",
   "metadata": {},
   "source": [
    "## Data extraction\n",
    "\n",
    "Extract only the required data from raw CSV and save to Pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18124af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from data_paths import RAW, OUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666c7431",
   "metadata": {},
   "source": [
    "Define the fles to be read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6df9771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the required cbg_group_regex\n",
    "CBG_CODE = '09009'\n",
    "COUNTY_NAME = 'new haven county'\n",
    "\n",
    "# define the data to be extracted\n",
    "\n",
    "# census files\n",
    "CBG_B01 = {\n",
    "    'file': 'cbg_b01.csv',\n",
    "    'cols': [0, 159, 160],\n",
    "    'names': ['cbg', 'B01003e1', 'B01003m1'],\n",
    "    'dtypes': {0: 'string', 159: np.int32, 160: np.int32}\n",
    "}\n",
    "\n",
    "CBG_B25 = {\n",
    "    'file': 'cbg_b25.csv',\n",
    "    'cols': [0, 187, 188],\n",
    "    'names': ['cbg', 'B25010e1', 'B25010m1'],\n",
    "    'dtypes': {0: 'string', 187: np.float32, 188: np.float32}\n",
    "}\n",
    "\n",
    "# patterns files\n",
    "PATTERNS_FEB = {\n",
    "    'file': 'feb2020_core_poi-patterns.csv',\n",
    "    'cols': [0, 25, 35],\n",
    "    'names': ['placekey', 'visitor_cbg', 'cbg'],\n",
    "    'dtypes': {0: 'string', 35: 'string', 25: 'string'},\n",
    "}\n",
    "\n",
    "PATTERNS_APR = {\n",
    "    'file': 'apr2020_core_poi-patterns.csv',\n",
    "    'cols': [0, 25, 35],\n",
    "    'names': ['placekey', 'visitor_cbg', 'cbg'],\n",
    "    'dtypes': {0: 'string', 35: 'string', 25: 'string'},\n",
    "}\n",
    "\n",
    "# Google mobility data\n",
    "GOOGLE_MOBILITY = {\n",
    "    'file': '2020_US_Region_Mobility_Report.csv',\n",
    "    'cols': [3, 8, 9, 10, 11, 12, 13, 14],\n",
    "    'names': ['county', 'date', 'retail_recreation', 'grocery_pharmacy', 'park', \n",
    "              'transit', 'workplace', 'residential'],\n",
    "    'date_cols': ['date'],\n",
    "    'dtypes': {3: 'string'},\n",
    "    'google': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c07cb24",
   "metadata": {},
   "source": [
    "Define the function to read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9be87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(data: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read raw data from a csv file.\n",
    "    :param data: contains info on the data to extract.\n",
    "    :returns: data in a pandas data frame.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not 'date_cols' in data:\n",
    "        data['date_cols'] = False\n",
    "    \n",
    "    iter_csv = pd.read_csv(f\"{RAW}{data['file']}\", usecols=data['cols'], dtype=data['dtypes'], \n",
    "                           parse_dates=data['date_cols'], header=0, names=data['names'], iterator=True, \n",
    "                           chunksize=1000)\n",
    "    \n",
    "    # google mobility data\n",
    "    if 'google' in data.keys():\n",
    "        \n",
    "        # filter new ha\n",
    "        df = pd.concat([chunk[chunk['county'].apply(lambda x: x.lower() == COUNTY_NAME\n",
    "                                                    if not pd.isnull(x) else False)] \n",
    "                        for chunk in iter_csv])\n",
    "    \n",
    "    else:\n",
    "        df = pd.concat([chunk[chunk['cbg'].apply(lambda x: x.startswith(CBG_CODE) \n",
    "                                                 if not pd.isnull(x) else False)] \n",
    "                        for chunk in iter_csv])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55595bdd",
   "metadata": {},
   "source": [
    "Read in the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9099a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.5 s, sys: 17.2 s, total: 43.7 s\n",
      "Wall time: 47.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "# read from csv\n",
    "df_google = read(GOOGLE_MOBILITY)\n",
    "df_pat_feb = read(PATTERNS_FEB)\n",
    "df_pat_apr = read(PATTERNS_APR)\n",
    "df_b01 = read(CBG_B01)\n",
    "df_b25 = read(CBG_B25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e484d79",
   "metadata": {},
   "source": [
    "Save data to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "127c7188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.1 ms, sys: 14.8 ms, total: 65.9 ms\n",
      "Wall time: 69.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# save to pickle\n",
    "df_google.to_pickle(f'{OUT}df_google.pkl')\n",
    "df_pat_feb.to_pickle(f'{OUT}df_pat_feb.pkl')\n",
    "df_pat_apr.to_pickle(f'{OUT}df_pat_apr.pkl')\n",
    "df_b01.to_pickle(f'{OUT}df_b01.pkl')\n",
    "df_b25.to_pickle(f'{OUT}df_b25.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
