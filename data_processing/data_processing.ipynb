{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12776816",
   "metadata": {},
   "source": [
    "### Data processing for network creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d21eb6b",
   "metadata": {},
   "source": [
    "Imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18124af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import getsizeof\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de639a",
   "metadata": {},
   "source": [
    "Some parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b35ef4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this to True if you want to reload from CSV, which takes longer. Otherwise data is loaded from pickled files.\n",
    "from_csv = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee476c0",
   "metadata": {},
   "source": [
    "Define loading behaviour ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6df9771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the required cbg_group_regex\n",
    "cbg_group_identifier = '09009'\n",
    "\n",
    "# define required columns and names for the two census files\n",
    "cbg_b01 = {\n",
    "    'file': 'cbg_b01.csv',\n",
    "    'cols': [0, 159, 160],\n",
    "    'names': ['cbg', 'B01003e1', 'B01003m1'],\n",
    "    'dtypes': {0: 'string', 159: np.int32, 160: np.int32}\n",
    "}\n",
    "\n",
    "cbg_b25 = {\n",
    "    'file': 'cbg_b25.csv',\n",
    "    'cols': [0, 187, 188],\n",
    "    'names': ['cbg', 'B25010e1', 'B25010m1'],\n",
    "    'dtypes': {0: 'string', 187: np.float32, 188: np.float32}\n",
    "}\n",
    "\n",
    "patterns_feb = {\n",
    "    'file': 'feb2020_core_poi-patterns.csv',\n",
    "    'cols': [0, 25, 35],\n",
    "    'names': ['placekey', 'visitor_cbg', 'cbg'],\n",
    "    'dtypes': {0: 'string', 35: 'string', 25: 'string'},\n",
    "}\n",
    "\n",
    "patterns_apr = {\n",
    "    'file': 'apr2020_core_poi-patterns.csv',\n",
    "    'cols': [0, 25, 35],\n",
    "    'names': ['placekey', 'visitor_cbg', 'cbg'],\n",
    "    'dtypes': {0: 'string', 35: 'string', 25: 'string'},\n",
    "}\n",
    "\n",
    "def read(data: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read raw data from a csv file.\n",
    "    :param data: contains info on the data to extract.\n",
    "    :returns: data in a pandas data frame.\n",
    "    \"\"\"\n",
    "    iter_csv = pd.read_csv(f\"data/{data['file']}\", usecols=data['cols'], dtype=data['dtypes'], \n",
    "                           header=0, names=data['names'], iterator=True, chunksize=1000)\n",
    "    \n",
    "    df = pd.concat([chunk[chunk['cbg'].apply(lambda x: x.startswith(cbg_group_identifier) if not pd.isnull(x) else False)] \n",
    "                    for chunk in iter_csv])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccda1a1",
   "metadata": {},
   "source": [
    "Load data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9099a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.9 s, sys: 8.66 s, total: 26.6 s\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if from_csv:\n",
    "    \n",
    "    # load from csv\n",
    "    df_pat_feb = read(patterns_feb)\n",
    "    df_pat_apr = read(patterns_apr)\n",
    "    df_b01 = read(cbg_b01)\n",
    "    df_b25 = read(cbg_b25)\n",
    "    \n",
    "    # save to pickle\n",
    "    df_pat_feb.to_pickle('data/df_pat_feb.pkl')\n",
    "    df_pat_apr.to_pickle('data/df_pat_apr.pkl')\n",
    "    df_b01.to_pickle('data/df_b01.pkl')\n",
    "    df_b25.to_pickle('data/df_b25.pkl')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # load from pickle\n",
    "    df_b01 = pd.read_pickle('data/df_b01.pkl')\n",
    "    df_b25 = pd.read_pickle('data/df_b25.pkl')\n",
    "    df_pat_feb = pd.read_pickle('data/df_pat_feb.pkl')\n",
    "    df_pat_apr = pd.read_pickle('data/df_pat_apr.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c2307a",
   "metadata": {},
   "source": [
    "Transform the CBG files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3afffdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "b01_col_names = {'B01003e1': 'population', 'B01003m1': 'population_me'}\n",
    "b25_col_names = {'B25010e1': 'household_size', 'B25010m1': 'household_size_me'}\n",
    "\n",
    "df_b01.rename(columns=b01_col_names, inplace=True)\n",
    "df_b25.rename(columns=b25_col_names, inplace=True)\n",
    "\n",
    "# convert margin of error to standard error\n",
    "z_score = 1.95996\n",
    "\n",
    "df_b01['population_se'] = df_b01['population_me'] / z_score\n",
    "df_b25['household_size_se'] = df_b25['household_size_me'] / z_score\n",
    "\n",
    "# merge data frames on census block\n",
    "df_merged = pd.merge(df_b01, df_b25, on='cbg', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d03cb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population: 857513.0\n",
      "Household size: 2.5217413902282715\n"
     ]
    }
   ],
   "source": [
    "# sanity checks with data from https://censusreporter.org/profiles/05000US09009-new-haven-county-ct/\n",
    "\n",
    "# population should be ~850,000 \n",
    "print('Population:', df_merged.sum()['population'])\n",
    "\n",
    "# mean household should be ~2.5\n",
    "print('Household size:', df_merged.mean()['household_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13cfc72",
   "metadata": {},
   "source": [
    "Save merged file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c9f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_pickle('data/df_pate.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83a533",
   "metadata": {},
   "source": [
    "Transform pattern files ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e342fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert JSON data to python dict\n",
    "df_pat_feb.visitor_cbg = df_pat_feb.visitor_cbg.apply(lambda x: json.loads(x))\n",
    "df_pat_apr.visitor_cbg = df_pat_apr.visitor_cbg.apply(lambda x: json.loads(x))\n",
    "\n",
    "# calculate total visitors\n",
    "df_pat_feb['total_visitors'] = df_pat_feb.visitor_cbg.apply(lambda x: sum(x.values()))\n",
    "df_pat_apr['total_visitors'] = df_pat_apr.visitor_cbg.apply(lambda x: sum(x.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c567abe",
   "metadata": {},
   "source": [
    "Create hashmap of total `CBG-CBG` connections..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ba530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cbg_cpg_hashmap(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Create a hashmap that contains the total counts of visits between two CBGs.\n",
    "    :param df: pattern data frame\n",
    "    :returns: hashmap with counts of visits\n",
    "    \"\"\"\n",
    "    hashmap = {}\n",
    "    for i, row in df.iterrows():\n",
    "        poi_cbg = row['cbg']\n",
    "        for cbg, count in row['visitor_cbg'].items():\n",
    "            cbg_cbg_id = f'{min(cbg, poi_cbg)}-{max(cbg, poi_cbg)}'\n",
    "            if cbg_cbg_id in hashmap:\n",
    "                hashmap[cbg_cbg_id] += count\n",
    "            else:\n",
    "                hashmap[cbg_cbg_id] = count\n",
    "    return hashmap\n",
    "\n",
    "def print_visit_count_info(title: str, visit_counts: dict, all_cbgs: list) -> None:\n",
    "    \"\"\"\n",
    "    Print info about the visit counts provided.\n",
    "    :param title: title to print out.\n",
    "    :param visit_counts: hashmap containing the count data.\n",
    "    :param all_cbgs: list of all cbgs.\n",
    "    \"\"\"\n",
    "    print(f'{title}:')\n",
    "    print(f\"{len(visit_counts)} out of a possible {len(all_cbgs)**2} edges.\")\n",
    "    print(f\"{sum(visit_counts.values())} unique visits.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aaa0bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Febuary:\n",
      "88686 out of a possible 394384 edges.\n",
      "1042364 unique visits.\n",
      "\n",
      "April:\n",
      "41335 out of a possible 394384 edges.\n",
      "411954 unique visits.\n",
      "\n",
      "CPU times: user 2.9 s, sys: 96.7 ms, total: 3 s\n",
      "Wall time: 2.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "visit_counts_feb = create_cbg_cpg_hashmap(df_pat_feb)\n",
    "visit_counts_apr = create_cbg_cpg_hashmap(df_pat_apr)\n",
    "\n",
    "print_visit_count_info(\"Febuary\", visit_counts_feb, df_merged.cbg.tolist())\n",
    "print_visit_count_info(\"April\", visit_counts_apr, df_merged.cbg.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e10922",
   "metadata": {},
   "source": [
    "Save visit counts to file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcad2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(visit_counts_feb, open('data/visit_counts_feb.pkl', 'wb'))\n",
    "pickle.dump(visit_counts_apr, open('data/visit_counts_apr.pkl', 'wb'))\n",
    "\n",
    "# read like this:\n",
    "# visit_counts_feb = pickle.load(open('data/visit_counts_feb.pkl', 'rb'))\n",
    "# visit_counts_apr = pickle.load(open('data/visit_counts_apr.pkl', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
