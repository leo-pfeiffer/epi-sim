{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12776816",
   "metadata": {},
   "source": [
    "### Data processing for network creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d21eb6b",
   "metadata": {},
   "source": [
    "Imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18124af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import getsizeof\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from typing import Tuple, Dict\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de639a",
   "metadata": {},
   "source": [
    "Some parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b35ef4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this to True if you want to reload from CSV, which takes longer. Otherwise data is loaded from pickled files.\n",
    "from_csv = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee476c0",
   "metadata": {},
   "source": [
    "Define loading behaviour ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6df9771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the required cbg_group_regex\n",
    "cbg_group_identifier = '09009'\n",
    "\n",
    "# define required columns and names for the two census files\n",
    "cbg_b01 = {\n",
    "    'file': 'cbg_b01.csv',\n",
    "    'cols': [0, 159, 160],\n",
    "    'names': ['cbg', 'B01003e1', 'B01003m1'],\n",
    "    'dtypes': {0: 'string', 159: np.int32, 160: np.int32}\n",
    "}\n",
    "\n",
    "cbg_b25 = {\n",
    "    'file': 'cbg_b25.csv',\n",
    "    'cols': [0, 187, 188],\n",
    "    'names': ['cbg', 'B25010e1', 'B25010m1'],\n",
    "    'dtypes': {0: 'string', 187: np.float32, 188: np.float32}\n",
    "}\n",
    "\n",
    "patterns_feb = {\n",
    "    'file': 'feb2020_core_poi-patterns.csv',\n",
    "    'cols': [0, 25, 35],\n",
    "    'names': ['placekey', 'visitor_cbg', 'cbg'],\n",
    "    'dtypes': {0: 'string', 35: 'string', 25: 'string'},\n",
    "}\n",
    "\n",
    "patterns_apr = {\n",
    "    'file': 'apr2020_core_poi-patterns.csv',\n",
    "    'cols': [0, 25, 35],\n",
    "    'names': ['placekey', 'visitor_cbg', 'cbg'],\n",
    "    'dtypes': {0: 'string', 35: 'string', 25: 'string'},\n",
    "}\n",
    "\n",
    "google_mobility = {\n",
    "    'file': '2020_US_Region_Mobility_Report.csv',\n",
    "    'cols': [3, 8, 9, 10, 11, 12, 13, 14],\n",
    "    'names': ['county', 'date', 'retail_recreation', 'grocery_pharmacy', 'park', \n",
    "              'transit', 'workplace', 'residential'],\n",
    "    'date_cols': ['date'],\n",
    "    'dtypes': {3: 'string'},\n",
    "    'google': True\n",
    "}\n",
    "\n",
    "def read(data: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read raw data from a csv file.\n",
    "    :param data: contains info on the data to extract.\n",
    "    :returns: data in a pandas data frame.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not 'date_cols' in data:\n",
    "        data['date_cols'] = False\n",
    "    \n",
    "    iter_csv = pd.read_csv(f\"data/{data['file']}\", usecols=data['cols'], dtype=data['dtypes'], \n",
    "                           parse_dates=data['date_cols'], header=0, names=data['names'], iterator=True, \n",
    "                           chunksize=1000)\n",
    "    \n",
    "    # google mobility data\n",
    "    if 'google' in data.keys():\n",
    "        df = pd.concat([chunk[chunk['county'].apply(lambda x: x.lower() == 'new haven county' \n",
    "                                                    if not pd.isnull(x) else False)] \n",
    "                        for chunk in iter_csv])\n",
    "    \n",
    "    else:\n",
    "        df = pd.concat([chunk[chunk['cbg'].apply(lambda x: x.startswith(cbg_group_identifier) \n",
    "                                                 if not pd.isnull(x) else False)] \n",
    "                        for chunk in iter_csv])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccda1a1",
   "metadata": {},
   "source": [
    "Load data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9099a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.3 ms, sys: 16.6 ms, total: 53.8 ms\n",
      "Wall time: 52.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if from_csv:\n",
    "    \n",
    "    # load from csv\n",
    "    df_google = read(google_mobility)\n",
    "    df_pat_feb = read(patterns_feb)\n",
    "    df_pat_apr = read(patterns_apr)\n",
    "    df_b01 = read(cbg_b01)\n",
    "    df_b25 = read(cbg_b25)\n",
    "    \n",
    "    # save to pickle\n",
    "    df_google.to_pickle('data/df_google.pkl')\n",
    "    df_pat_feb.to_pickle('data/df_pat_feb.pkl')\n",
    "    df_pat_apr.to_pickle('data/df_pat_apr.pkl')\n",
    "    df_b01.to_pickle('data/df_b01.pkl')\n",
    "    df_b25.to_pickle('data/df_b25.pkl')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # load from pickle\n",
    "    df_b01 = pd.read_pickle('data/df_b01.pkl')\n",
    "    df_b25 = pd.read_pickle('data/df_b25.pkl')\n",
    "    df_pat_feb = pd.read_pickle('data/df_pat_feb.pkl')\n",
    "    df_pat_apr = pd.read_pickle('data/df_pat_apr.pkl')\n",
    "    df_google = pd.read_pickle('data/df_google.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c2307a",
   "metadata": {},
   "source": [
    "Transform the CBG files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3afffdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "b01_col_names = {'B01003e1': 'population', 'B01003m1': 'population_me'}\n",
    "b25_col_names = {'B25010e1': 'household_size', 'B25010m1': 'household_size_me'}\n",
    "\n",
    "df_b01.rename(columns=b01_col_names, inplace=True)\n",
    "df_b25.rename(columns=b25_col_names, inplace=True)\n",
    "\n",
    "# convert margin of error to standard error\n",
    "z_score = 1.95996\n",
    "\n",
    "df_b01['population_se'] = df_b01['population_me'] / z_score\n",
    "df_b25['household_size_se'] = df_b25['household_size_me'] / z_score\n",
    "\n",
    "# merge data frames on census block\n",
    "df_merged = pd.merge(df_b01, df_b25, on='cbg', how='outer')\n",
    "\n",
    "# add proportional population\n",
    "df_merged['population_prop'] = df_merged['population'] / df_merged['population'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d03cb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population: 857513.0\n",
      "Household size: 2.5217413902282715\n"
     ]
    }
   ],
   "source": [
    "# sanity checks with data from https://censusreporter.org/profiles/05000US09009-new-haven-county-ct/\n",
    "\n",
    "# population should be ~850,000 \n",
    "print('Population:', df_merged.sum()['population'])\n",
    "\n",
    "# mean household should be ~2.5\n",
    "print('Household size:', df_merged.mean()['household_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "253926bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>population_me</th>\n",
       "      <th>population_se</th>\n",
       "      <th>household_size</th>\n",
       "      <th>household_size_me</th>\n",
       "      <th>household_size_se</th>\n",
       "      <th>population_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>628.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>626.000000</td>\n",
       "      <td>626.000000</td>\n",
       "      <td>626.000000</td>\n",
       "      <td>628.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1365.466561</td>\n",
       "      <td>342.968153</td>\n",
       "      <td>174.987323</td>\n",
       "      <td>2.521741</td>\n",
       "      <td>0.448115</td>\n",
       "      <td>0.228635</td>\n",
       "      <td>0.001592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>652.336689</td>\n",
       "      <td>137.227720</td>\n",
       "      <td>70.015572</td>\n",
       "      <td>0.476634</td>\n",
       "      <td>0.192414</td>\n",
       "      <td>0.098173</td>\n",
       "      <td>0.000761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.122574</td>\n",
       "      <td>1.210000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.045919</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>886.000000</td>\n",
       "      <td>249.500000</td>\n",
       "      <td>127.298516</td>\n",
       "      <td>2.190000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.163269</td>\n",
       "      <td>0.001033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1253.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>165.819711</td>\n",
       "      <td>2.520000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.209188</td>\n",
       "      <td>0.001461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1716.250000</td>\n",
       "      <td>405.250000</td>\n",
       "      <td>206.764424</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.275516</td>\n",
       "      <td>0.002001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4063.000000</td>\n",
       "      <td>1047.000000</td>\n",
       "      <td>534.194575</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>0.698994</td>\n",
       "      <td>0.004738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        population  population_me  population_se  household_size  \\\n",
       "count   628.000000     628.000000     628.000000      626.000000   \n",
       "mean   1365.466561     342.968153     174.987323        2.521741   \n",
       "std     652.336689     137.227720      70.015572        0.476634   \n",
       "min       0.000000      12.000000       6.122574        1.210000   \n",
       "25%     886.000000     249.500000     127.298516        2.190000   \n",
       "50%    1253.000000     325.000000     165.819711        2.520000   \n",
       "75%    1716.250000     405.250000     206.764424        2.860000   \n",
       "max    4063.000000    1047.000000     534.194575        4.000000   \n",
       "\n",
       "       household_size_me  household_size_se  population_prop  \n",
       "count         626.000000         626.000000       628.000000  \n",
       "mean            0.448115           0.228635         0.001592  \n",
       "std             0.192414           0.098173         0.000761  \n",
       "min             0.090000           0.045919         0.000000  \n",
       "25%             0.320000           0.163269         0.001033  \n",
       "50%             0.410000           0.209188         0.001461  \n",
       "75%             0.540000           0.275516         0.002001  \n",
       "max             1.370000           0.698994         0.004738  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the summary stats for plausibility\n",
    "df_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24c9ab78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cbg</th>\n",
       "      <th>population</th>\n",
       "      <th>population_me</th>\n",
       "      <th>population_se</th>\n",
       "      <th>household_size</th>\n",
       "      <th>household_size_me</th>\n",
       "      <th>household_size_se</th>\n",
       "      <th>population_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>090093614022</td>\n",
       "      <td>1476</td>\n",
       "      <td>218</td>\n",
       "      <td>111.226760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>090099900000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>6.122574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cbg  population  population_me  population_se  household_size  \\\n",
       "622  090093614022        1476            218     111.226760             NaN   \n",
       "627  090099900000           0             12       6.122574             NaN   \n",
       "\n",
       "     household_size_me  household_size_se  population_prop  \n",
       "622                NaN                NaN         0.001721  \n",
       "627                NaN                NaN         0.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for NA values\n",
    "df_merged.iloc[[x > 0 for x in df_merged.isna().sum(axis=1)], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8996f2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we only have two rows with NA, we can impute them with the mean\n",
    "df_merged.fillna(df_merged.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13cfc72",
   "metadata": {},
   "source": [
    "Save merged file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce6c9f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = df_merged.set_index('cbg').to_dict('index')\n",
    "pickle.dump(demographics, open('data/demographics.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83a533",
   "metadata": {},
   "source": [
    "Transform pattern files ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e342fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert JSON data to python dict\n",
    "df_pat_feb.visitor_cbg = df_pat_feb.visitor_cbg.apply(lambda x: json.loads(x))\n",
    "df_pat_apr.visitor_cbg = df_pat_apr.visitor_cbg.apply(lambda x: json.loads(x))\n",
    "\n",
    "# calculate total visitors\n",
    "df_pat_feb['total_visitors'] = df_pat_feb.visitor_cbg.apply(lambda x: sum(x.values()))\n",
    "df_pat_apr['total_visitors'] = df_pat_apr.visitor_cbg.apply(lambda x: sum(x.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe3b366",
   "metadata": {},
   "source": [
    "Transform Google mobility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aa93f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only february and april\n",
    "\n",
    "def _month_filter(keep: [], x):\n",
    "    return x in keep\n",
    "\n",
    "feb_apr_filter = partial(_month_filter, [2, 4])\n",
    "\n",
    "df_google = df_google[df_google.date.apply(lambda x: feb_apr_filter(x.month))].set_index('date')\n",
    "df_google.drop('county', axis=1, inplace=True)\n",
    "\n",
    "# rebase\n",
    "df_google += 100\n",
    "\n",
    "# df_google = df_google.groupby(df_google.index.month).agg([np.mean, np.std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5877f409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retail_recreation</th>\n",
       "      <th>grocery_pharmacy</th>\n",
       "      <th>park</th>\n",
       "      <th>transit</th>\n",
       "      <th>workplace</th>\n",
       "      <th>residential</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-15</th>\n",
       "      <td>103.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-16</th>\n",
       "      <td>104.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17</th>\n",
       "      <td>110.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-18</th>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-19</th>\n",
       "      <td>102.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-20</th>\n",
       "      <td>103.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-21</th>\n",
       "      <td>100.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-22</th>\n",
       "      <td>108.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-23</th>\n",
       "      <td>107.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24</th>\n",
       "      <td>101.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25</th>\n",
       "      <td>101.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-26</th>\n",
       "      <td>106.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27</th>\n",
       "      <td>106.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28</th>\n",
       "      <td>105.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-29</th>\n",
       "      <td>111.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>63.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-02</th>\n",
       "      <td>59.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-03</th>\n",
       "      <td>56.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-04</th>\n",
       "      <td>54.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-05</th>\n",
       "      <td>50.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-06</th>\n",
       "      <td>61.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-07</th>\n",
       "      <td>61.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-08</th>\n",
       "      <td>56.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-09</th>\n",
       "      <td>54.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-10</th>\n",
       "      <td>56.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-11</th>\n",
       "      <td>56.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-12</th>\n",
       "      <td>37.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-13</th>\n",
       "      <td>43.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-14</th>\n",
       "      <td>64.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-15</th>\n",
       "      <td>67.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-16</th>\n",
       "      <td>64.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-17</th>\n",
       "      <td>61.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-18</th>\n",
       "      <td>52.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-19</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-20</th>\n",
       "      <td>64.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-21</th>\n",
       "      <td>57.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-22</th>\n",
       "      <td>64.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-23</th>\n",
       "      <td>62.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-24</th>\n",
       "      <td>57.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-25</th>\n",
       "      <td>65.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-26</th>\n",
       "      <td>51.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-27</th>\n",
       "      <td>63.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-28</th>\n",
       "      <td>71.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-29</th>\n",
       "      <td>67.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30</th>\n",
       "      <td>61.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            retail_recreation  grocery_pharmacy   park  transit  workplace  \\\n",
       "date                                                                         \n",
       "2020-02-15              103.0              96.0  108.0    115.0       98.0   \n",
       "2020-02-16              104.0              97.0   97.0    106.0       99.0   \n",
       "2020-02-17              110.0             102.0  117.0    110.0       73.0   \n",
       "2020-02-18              100.0              96.0   86.0    102.0       92.0   \n",
       "2020-02-19              102.0              97.0  111.0    105.0       99.0   \n",
       "2020-02-20              103.0              98.0  103.0    103.0      100.0   \n",
       "2020-02-21              100.0              95.0   96.0    102.0       99.0   \n",
       "2020-02-22              108.0             100.0  156.0    115.0      104.0   \n",
       "2020-02-23              107.0             102.0  158.0    115.0      103.0   \n",
       "2020-02-24              101.0             102.0  132.0    105.0      104.0   \n",
       "2020-02-25              101.0              99.0  102.0    102.0      102.0   \n",
       "2020-02-26              106.0             101.0  103.0    104.0      102.0   \n",
       "2020-02-27              106.0             102.0  102.0    106.0      103.0   \n",
       "2020-02-28              105.0             102.0  103.0    103.0      103.0   \n",
       "2020-02-29              111.0             104.0  121.0    108.0      103.0   \n",
       "2020-04-01               63.0              90.0  110.0     60.0       50.0   \n",
       "2020-04-02               59.0              90.0   85.0     56.0       50.0   \n",
       "2020-04-03               56.0              90.0   59.0     46.0       50.0   \n",
       "2020-04-04               54.0              88.0  151.0     51.0       65.0   \n",
       "2020-04-05               50.0              77.0  107.0     42.0       62.0   \n",
       "2020-04-06               61.0              87.0  126.0     57.0       50.0   \n",
       "2020-04-07               61.0              86.0  112.0     59.0       48.0   \n",
       "2020-04-08               56.0              83.0   83.0     56.0       47.0   \n",
       "2020-04-09               54.0              83.0   63.0     49.0       46.0   \n",
       "2020-04-10               56.0              90.0   79.0     44.0       38.0   \n",
       "2020-04-11               56.0              92.0  143.0     50.0       61.0   \n",
       "2020-04-12               37.0              52.0  111.0     41.0       56.0   \n",
       "2020-04-13               43.0              60.0   42.0     43.0       46.0   \n",
       "2020-04-14               64.0              86.0  112.0     61.0       49.0   \n",
       "2020-04-15               67.0              86.0  103.0     58.0       49.0   \n",
       "2020-04-16               64.0              85.0   92.0     57.0       49.0   \n",
       "2020-04-17               61.0              82.0   91.0     51.0       50.0   \n",
       "2020-04-18               52.0              78.0   82.0     45.0       63.0   \n",
       "2020-04-19               62.0              80.0  159.0     50.0       67.0   \n",
       "2020-04-20               64.0              82.0   94.0     58.0       51.0   \n",
       "2020-04-21               57.0              75.0   64.0     55.0       49.0   \n",
       "2020-04-22               64.0              83.0   90.0     61.0       50.0   \n",
       "2020-04-23               62.0              81.0   84.0     57.0       51.0   \n",
       "2020-04-24               57.0              76.0   61.0     47.0       50.0   \n",
       "2020-04-25               65.0              84.0  216.0     60.0       67.0   \n",
       "2020-04-26               51.0              72.0   58.0     40.0       64.0   \n",
       "2020-04-27               63.0              82.0   73.0     57.0       52.0   \n",
       "2020-04-28               71.0              86.0  132.0     66.0       52.0   \n",
       "2020-04-29               67.0              83.0   95.0     62.0       51.0   \n",
       "2020-04-30               61.0              82.0   69.0     56.0       51.0   \n",
       "\n",
       "            residential  \n",
       "date                     \n",
       "2020-02-15        100.0  \n",
       "2020-02-16        100.0  \n",
       "2020-02-17        106.0  \n",
       "2020-02-18        103.0  \n",
       "2020-02-19        100.0  \n",
       "2020-02-20        101.0  \n",
       "2020-02-21        101.0  \n",
       "2020-02-22         98.0  \n",
       "2020-02-23         99.0  \n",
       "2020-02-24         99.0  \n",
       "2020-02-25        100.0  \n",
       "2020-02-26         99.0  \n",
       "2020-02-27        100.0  \n",
       "2020-02-28         99.0  \n",
       "2020-02-29         98.0  \n",
       "2020-04-01        120.0  \n",
       "2020-04-02        122.0  \n",
       "2020-04-03        125.0  \n",
       "2020-04-04        114.0  \n",
       "2020-04-05        113.0  \n",
       "2020-04-06        120.0  \n",
       "2020-04-07        121.0  \n",
       "2020-04-08        122.0  \n",
       "2020-04-09        124.0  \n",
       "2020-04-10        127.0  \n",
       "2020-04-11        114.0  \n",
       "2020-04-12        113.0  \n",
       "2020-04-13        125.0  \n",
       "2020-04-14        121.0  \n",
       "2020-04-15        121.0  \n",
       "2020-04-16        122.0  \n",
       "2020-04-17        123.0  \n",
       "2020-04-18        116.0  \n",
       "2020-04-19        111.0  \n",
       "2020-04-20        120.0  \n",
       "2020-04-21        123.0  \n",
       "2020-04-22        121.0  \n",
       "2020-04-23        122.0  \n",
       "2020-04-24        125.0  \n",
       "2020-04-25        111.0  \n",
       "2020-04-26        114.0  \n",
       "2020-04-27        120.0  \n",
       "2020-04-28        113.0  \n",
       "2020-04-29        120.0  \n",
       "2020-04-30        122.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_google"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c7198",
   "metadata": {},
   "source": [
    "Save mobility data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61009de9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "google_mobility_agg = {}\n",
    "for month in [2, 4]:\n",
    "    google_mobility_agg[month] = {}\n",
    "    df_sub = df_google[df_google.index.month == month]\n",
    "    for col in df_google.columns.tolist():\n",
    "        google_mobility_agg[month][col] = df_sub[col].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35dd9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(google_mobility_agg, open('data/google_mobility_agg.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c567abe",
   "metadata": {},
   "source": [
    "Create hashmap of total `CBG-CBG` connections..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88ba530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_count_hashmaps(df: pd.DataFrame, all_cbgs: set) -> Tuple[Dict, Dict]:\n",
    "    \"\"\"\n",
    "    Create two hashmaps:\n",
    "    - comb_counts: total counts of visits between two CBGs\n",
    "    - trip_counts: total counts of all trips taken from each CBG\n",
    "    :param df: pattern data frame\n",
    "    :param all_cbgs: set containing all CBGs\n",
    "    :returns: Tuple with two hashmaps\n",
    "    \"\"\"\n",
    "    \n",
    "    comb_counts = {}\n",
    "    trip_counts = {}\n",
    "    for i, row in df.iterrows():\n",
    "\n",
    "        # CBG of the POI\n",
    "        poi_cbg = row['cbg']\n",
    "\n",
    "        for cbg, count in row['visitor_cbg'].items():\n",
    "            \n",
    "            # ignore visits from other counties\n",
    "            if cbg not in all_cbgs or poi_cbg not in all_cbgs:\n",
    "                continue\n",
    "            \n",
    "            # Combination from visitor CBG to POI CBG\n",
    "            cbg_comb = (cbg, poi_cbg)\n",
    "            \n",
    "            # add count to combination counts\n",
    "            if cbg_comb in comb_counts:\n",
    "                comb_counts[cbg_comb] += count\n",
    "            else:\n",
    "                comb_counts[cbg_comb] = count\n",
    "            \n",
    "            # add count to trip counts\n",
    "            if cbg in trip_counts:\n",
    "                trip_counts[cbg] += count\n",
    "\n",
    "            else:\n",
    "                trip_counts[cbg] = count\n",
    "                \n",
    "    return comb_counts, trip_counts\n",
    "\n",
    "def print_visit_count_info(title: str, visit_counts: dict, all_cbgs: list):\n",
    "    \"\"\"\n",
    "    Print info about the visit counts provided.\n",
    "    :param title: title to print out.\n",
    "    :param visit_counts: hashmap containing the count data.\n",
    "    :param all_cbgs: list of all cbgs.\n",
    "    \"\"\"\n",
    "    print(f'{title}:')\n",
    "    print(f\"{len(visit_counts)} out of a possible {len(all_cbgs)**2} edges.\")\n",
    "    print(f\"{sum(visit_counts.values())} unique visits.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aaa0bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Febuary:\n",
      "52336 out of a possible 394384 edges.\n",
      "777780 unique visits.\n",
      "\n",
      "April:\n",
      "29715 out of a possible 394384 edges.\n",
      "327589 unique visits.\n",
      "\n",
      "CPU times: user 3.31 s, sys: 30.9 ms, total: 3.34 s\n",
      "Wall time: 3.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "comb_counts_feb, trip_counts_feb = create_count_hashmaps(df_pat_feb, set(df_merged.cbg.tolist()))\n",
    "comb_counts_apr, trip_counts_apr = create_count_hashmaps(df_pat_apr, set(df_merged.cbg.tolist()))\n",
    "\n",
    "print_visit_count_info(\"Febuary\", comb_counts_feb, df_merged.cbg.tolist())\n",
    "print_visit_count_info(\"April\", comb_counts_apr, df_merged.cbg.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e10922",
   "metadata": {},
   "source": [
    "Save visit counts to file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcad2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(comb_counts_feb, open('data/comb_counts_feb.pkl', 'wb'))\n",
    "pickle.dump(comb_counts_apr, open('data/comb_counts_apr.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(trip_counts_feb, open('data/trip_counts_feb.pkl', 'wb'))\n",
    "pickle.dump(trip_counts_apr, open('data/trip_counts_apr.pkl', 'wb'))\n",
    "\n",
    "# read like this:\n",
    "# comb_counts_feb = pickle.load(open('data/comb_counts_feb.pkl', 'rb'))\n",
    "# comb_counts_apr = pickle.load(open('data/comb_counts_apr.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f5a60a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
