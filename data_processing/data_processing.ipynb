{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12776816",
   "metadata": {},
   "source": [
    "### Data processing for network creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d21eb6b",
   "metadata": {},
   "source": [
    "Imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18124af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import getsizeof\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from typing import Tuple, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de639a",
   "metadata": {},
   "source": [
    "Some parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b35ef4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this to True if you want to reload from CSV, which takes longer. Otherwise data is loaded from pickled files.\n",
    "from_csv = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee476c0",
   "metadata": {},
   "source": [
    "Define loading behaviour ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6df9771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the required cbg_group_regex\n",
    "cbg_group_identifier = '09009'\n",
    "\n",
    "# define required columns and names for the two census files\n",
    "cbg_b01 = {\n",
    "    'file': 'cbg_b01.csv',\n",
    "    'cols': [0, 159, 160],\n",
    "    'names': ['cbg', 'B01003e1', 'B01003m1'],\n",
    "    'dtypes': {0: 'string', 159: np.int32, 160: np.int32}\n",
    "}\n",
    "\n",
    "cbg_b25 = {\n",
    "    'file': 'cbg_b25.csv',\n",
    "    'cols': [0, 187, 188],\n",
    "    'names': ['cbg', 'B25010e1', 'B25010m1'],\n",
    "    'dtypes': {0: 'string', 187: np.float32, 188: np.float32}\n",
    "}\n",
    "\n",
    "patterns_feb = {\n",
    "    'file': 'feb2020_core_poi-patterns.csv',\n",
    "    'cols': [0, 25, 35],\n",
    "    'names': ['placekey', 'visitor_cbg', 'cbg'],\n",
    "    'dtypes': {0: 'string', 35: 'string', 25: 'string'},\n",
    "}\n",
    "\n",
    "patterns_apr = {\n",
    "    'file': 'apr2020_core_poi-patterns.csv',\n",
    "    'cols': [0, 25, 35],\n",
    "    'names': ['placekey', 'visitor_cbg', 'cbg'],\n",
    "    'dtypes': {0: 'string', 35: 'string', 25: 'string'},\n",
    "}\n",
    "\n",
    "def read(data: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read raw data from a csv file.\n",
    "    :param data: contains info on the data to extract.\n",
    "    :returns: data in a pandas data frame.\n",
    "    \"\"\"\n",
    "    iter_csv = pd.read_csv(f\"data/{data['file']}\", usecols=data['cols'], dtype=data['dtypes'], \n",
    "                           header=0, names=data['names'], iterator=True, chunksize=1000)\n",
    "    \n",
    "    df = pd.concat([chunk[chunk['cbg'].apply(lambda x: x.startswith(cbg_group_identifier) if not pd.isnull(x) else False)] \n",
    "                    for chunk in iter_csv])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccda1a1",
   "metadata": {},
   "source": [
    "Load data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9099a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 ms, sys: 31.6 ms, total: 54.6 ms\n",
      "Wall time: 54.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if from_csv:\n",
    "    \n",
    "    # load from csv\n",
    "    df_pat_feb = read(patterns_feb)\n",
    "    df_pat_apr = read(patterns_apr)\n",
    "    df_b01 = read(cbg_b01)\n",
    "    df_b25 = read(cbg_b25)\n",
    "    \n",
    "    # save to pickle\n",
    "    df_pat_feb.to_pickle('data/df_pat_feb.pkl')\n",
    "    df_pat_apr.to_pickle('data/df_pat_apr.pkl')\n",
    "    df_b01.to_pickle('data/df_b01.pkl')\n",
    "    df_b25.to_pickle('data/df_b25.pkl')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # load from pickle\n",
    "    df_b01 = pd.read_pickle('data/df_b01.pkl')\n",
    "    df_b25 = pd.read_pickle('data/df_b25.pkl')\n",
    "    df_pat_feb = pd.read_pickle('data/df_pat_feb.pkl')\n",
    "    df_pat_apr = pd.read_pickle('data/df_pat_apr.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c2307a",
   "metadata": {},
   "source": [
    "Transform the CBG files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3afffdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "b01_col_names = {'B01003e1': 'population', 'B01003m1': 'population_me'}\n",
    "b25_col_names = {'B25010e1': 'household_size', 'B25010m1': 'household_size_me'}\n",
    "\n",
    "df_b01.rename(columns=b01_col_names, inplace=True)\n",
    "df_b25.rename(columns=b25_col_names, inplace=True)\n",
    "\n",
    "# convert margin of error to standard error\n",
    "z_score = 1.95996\n",
    "\n",
    "df_b01['population_se'] = df_b01['population_me'] / z_score\n",
    "df_b25['household_size_se'] = df_b25['household_size_me'] / z_score\n",
    "\n",
    "# merge data frames on census block\n",
    "df_merged = pd.merge(df_b01, df_b25, on='cbg', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d03cb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population: 857513.0\n",
      "Household size: 2.5217413902282715\n"
     ]
    }
   ],
   "source": [
    "# sanity checks with data from https://censusreporter.org/profiles/05000US09009-new-haven-county-ct/\n",
    "\n",
    "# population should be ~850,000 \n",
    "print('Population:', df_merged.sum()['population'])\n",
    "\n",
    "# mean household should be ~2.5\n",
    "print('Household size:', df_merged.mean()['household_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "253926bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>population_me</th>\n",
       "      <th>population_se</th>\n",
       "      <th>household_size</th>\n",
       "      <th>household_size_me</th>\n",
       "      <th>household_size_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>628.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>626.000000</td>\n",
       "      <td>626.000000</td>\n",
       "      <td>626.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1365.466561</td>\n",
       "      <td>342.968153</td>\n",
       "      <td>174.987323</td>\n",
       "      <td>2.521741</td>\n",
       "      <td>0.448115</td>\n",
       "      <td>0.228635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>652.336689</td>\n",
       "      <td>137.227720</td>\n",
       "      <td>70.015572</td>\n",
       "      <td>0.476634</td>\n",
       "      <td>0.192414</td>\n",
       "      <td>0.098173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.122574</td>\n",
       "      <td>1.210000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.045919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>886.000000</td>\n",
       "      <td>249.500000</td>\n",
       "      <td>127.298516</td>\n",
       "      <td>2.190000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.163269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1253.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>165.819711</td>\n",
       "      <td>2.520000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.209188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1716.250000</td>\n",
       "      <td>405.250000</td>\n",
       "      <td>206.764424</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.275516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4063.000000</td>\n",
       "      <td>1047.000000</td>\n",
       "      <td>534.194575</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>0.698994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        population  population_me  population_se  household_size  \\\n",
       "count   628.000000     628.000000     628.000000      626.000000   \n",
       "mean   1365.466561     342.968153     174.987323        2.521741   \n",
       "std     652.336689     137.227720      70.015572        0.476634   \n",
       "min       0.000000      12.000000       6.122574        1.210000   \n",
       "25%     886.000000     249.500000     127.298516        2.190000   \n",
       "50%    1253.000000     325.000000     165.819711        2.520000   \n",
       "75%    1716.250000     405.250000     206.764424        2.860000   \n",
       "max    4063.000000    1047.000000     534.194575        4.000000   \n",
       "\n",
       "       household_size_me  household_size_se  \n",
       "count         626.000000         626.000000  \n",
       "mean            0.448115           0.228635  \n",
       "std             0.192414           0.098173  \n",
       "min             0.090000           0.045919  \n",
       "25%             0.320000           0.163269  \n",
       "50%             0.410000           0.209188  \n",
       "75%             0.540000           0.275516  \n",
       "max             1.370000           0.698994  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the summary stats for plausibility\n",
    "df_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24c9ab78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cbg</th>\n",
       "      <th>population</th>\n",
       "      <th>population_me</th>\n",
       "      <th>population_se</th>\n",
       "      <th>household_size</th>\n",
       "      <th>household_size_me</th>\n",
       "      <th>household_size_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>090093614022</td>\n",
       "      <td>1476</td>\n",
       "      <td>218</td>\n",
       "      <td>111.226760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>090099900000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>6.122574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cbg  population  population_me  population_se  household_size  \\\n",
       "622  090093614022        1476            218     111.226760             NaN   \n",
       "627  090099900000           0             12       6.122574             NaN   \n",
       "\n",
       "     household_size_me  household_size_se  \n",
       "622                NaN                NaN  \n",
       "627                NaN                NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for NA values\n",
    "df_merged.iloc[[x > 0 for x in df_merged.isna().sum(axis=1)], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8996f2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we only have two rows with NA, we can impute them with the mean\n",
    "df_merged.fillna(df_merged.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13cfc72",
   "metadata": {},
   "source": [
    "Save merged file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce6c9f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = df_merged.set_index('cbg').to_dict('index')\n",
    "pickle.dump(demographics, open('data/demographics.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83a533",
   "metadata": {},
   "source": [
    "Transform pattern files ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e342fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert JSON data to python dict\n",
    "df_pat_feb.visitor_cbg = df_pat_feb.visitor_cbg.apply(lambda x: json.loads(x))\n",
    "df_pat_apr.visitor_cbg = df_pat_apr.visitor_cbg.apply(lambda x: json.loads(x))\n",
    "\n",
    "# calculate total visitors\n",
    "df_pat_feb['total_visitors'] = df_pat_feb.visitor_cbg.apply(lambda x: sum(x.values()))\n",
    "df_pat_apr['total_visitors'] = df_pat_apr.visitor_cbg.apply(lambda x: sum(x.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c567abe",
   "metadata": {},
   "source": [
    "Create hashmap of total `CBG-CBG` connections..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88ba530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_count_hashmaps(df: pd.DataFrame, all_cbgs: set) -> Tuple[Dict, Dict]:\n",
    "    \"\"\"\n",
    "    Create two hashmaps:\n",
    "    - comb_counts: total counts of visits between two CBGs\n",
    "    - trip_counts: total counts of all trips taken from each CBG\n",
    "    :param df: pattern data frame\n",
    "    :param all_cbgs: set containing all CBGs\n",
    "    :returns: Tuple with two hashmaps\n",
    "    \"\"\"\n",
    "    \n",
    "    comb_counts = {}\n",
    "    trip_counts = {}\n",
    "    for i, row in df.iterrows():\n",
    "\n",
    "        # CBG of the POI\n",
    "        poi_cbg = row['cbg']\n",
    "\n",
    "        for cbg, count in row['visitor_cbg'].items():\n",
    "            \n",
    "            # ignore visits from other counties\n",
    "            if cbg not in all_cbgs or poi_cbg not in all_cbgs:\n",
    "                continue\n",
    "            \n",
    "            # Combination from visitor CBG to POI CBG\n",
    "            cbg_comb = (cbg, poi_cbg)\n",
    "            \n",
    "            # add count to combination counts\n",
    "            if cbg_comb in comb_counts:\n",
    "                comb_counts[cbg_comb] += count\n",
    "            else:\n",
    "                comb_counts[cbg_comb] = count\n",
    "            \n",
    "            # add count to trip counts\n",
    "            if cbg in trip_counts:\n",
    "                trip_counts[cbg] += count\n",
    "\n",
    "            else:\n",
    "                trip_counts[cbg] = count\n",
    "                \n",
    "    return comb_counts, trip_counts\n",
    "\n",
    "def print_visit_count_info(title: str, visit_counts: dict, all_cbgs: list):\n",
    "    \"\"\"\n",
    "    Print info about the visit counts provided.\n",
    "    :param title: title to print out.\n",
    "    :param visit_counts: hashmap containing the count data.\n",
    "    :param all_cbgs: list of all cbgs.\n",
    "    \"\"\"\n",
    "    print(f'{title}:')\n",
    "    print(f\"{len(visit_counts)} out of a possible {len(all_cbgs)**2} edges.\")\n",
    "    print(f\"{sum(visit_counts.values())} unique visits.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8aaa0bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Febuary:\n",
      "52336 out of a possible 394384 edges.\n",
      "777780 unique visits.\n",
      "\n",
      "April:\n",
      "29715 out of a possible 394384 edges.\n",
      "327589 unique visits.\n",
      "\n",
      "CPU times: user 3.18 s, sys: 0 ns, total: 3.18 s\n",
      "Wall time: 3.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "comb_counts_feb, trip_counts_feb = create_count_hashmaps(df_pat_feb, set(df_merged.cbg.tolist()))\n",
    "comb_counts_apr, trip_counts_apr = create_count_hashmaps(df_pat_apr, set(df_merged.cbg.tolist()))\n",
    "\n",
    "print_visit_count_info(\"Febuary\", comb_counts_feb, df_merged.cbg.tolist())\n",
    "print_visit_count_info(\"April\", comb_counts_apr, df_merged.cbg.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e10922",
   "metadata": {},
   "source": [
    "Save visit counts to file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcad2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(comb_counts_feb, open('data/comb_counts_feb.pkl', 'wb'))\n",
    "pickle.dump(comb_counts_apr, open('data/comb_counts_apr.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(trip_counts_feb, open('data/trip_counts_feb.pkl', 'wb'))\n",
    "pickle.dump(trip_counts_apr, open('data/trip_counts_apr.pkl', 'wb'))\n",
    "\n",
    "# read like this:\n",
    "# comb_counts_feb = pickle.load(open('data/comb_counts_feb.pkl', 'rb'))\n",
    "# comb_counts_apr = pickle.load(open('data/comb_counts_apr.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b93416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
